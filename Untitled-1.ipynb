{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simulate_diffusion(motion_data, num_steps=1, beta_start=0.000001, beta_end=0.0002):\n",
    "    \"\"\"\n",
    "    模拟扩散过程，为运动数据逐步添加高斯噪声。\n",
    "\n",
    "    参数：\n",
    "        motion_data (numpy.ndarray): 原始运动数据，形状为 [nframes, njoints, nfeats]。\n",
    "        num_steps (int): 扩散过程的时间步数。\n",
    "        beta_start (float): 初始噪声强度。\n",
    "        beta_end (float): 最终噪声强度。\n",
    "\n",
    "    返回：\n",
    "        numpy.ndarray: 带噪声的最终数据，形状与输入相同 [nframes, njoints, nfeats]。\n",
    "    \"\"\"\n",
    "    # 确保输入数据是 numpy 数组\n",
    "    motion_data = np.asarray(motion_data)\n",
    "    \n",
    "    # 创建线性递增的噪声强度\n",
    "    betas = np.linspace(beta_start, beta_end, num_steps)\n",
    "    \n",
    "    # 初始化带噪声的数据\n",
    "    noisy_data = motion_data.copy()\n",
    "    \n",
    "    # 逐步添加噪声\n",
    "    for beta in betas:\n",
    "        noise = np.sqrt(beta) * np.random.randn(*motion_data.shape)\n",
    "        noisy_data = np.sqrt(1 - beta) * noisy_data + noise\n",
    "    \n",
    "    return noisy_data\n",
    "\n",
    "# 示例用法\n",
    "# 假设 motion_data 是形状 [nframes, njoints, nfeats] 的数据\n",
    "# motion_data = np.load('path_to_data.npy')  # 加载数据\n",
    "# noisy_motion_data = simulate_diffusion(motion_data)\n",
    "\n",
    "# 查看结果\n",
    "# print(f\"Noisy motion data shape: {noisy_motion_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 22, 3)\n",
      "Animation saved at: ./animations/0_/01.mp4\n",
      "(120, 22, 3)\n",
      "Animation saved at: ./animations/1_/01.mp4\n",
      "(120, 22, 3)\n",
      "Animation saved at: ./animations/2_/01.mp4\n",
      "(120, 22, 3)\n",
      "Animation saved at: ./animations/3_/01.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data_loaders.humanml.utils.paramUtil import t2m_kinematic_chain  # 骨架定义\n",
    "from data_loaders.humanml.utils.plot_script import plot_3d_motion  # 动画生成函数\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_visualize_motion(npy_path, out_dir, text, step, fps=20,beta_end=0.0002):\n",
    "    \"\"\"\n",
    "    从指定的 .npy 文件加载运动数据，并生成 3D 动画。\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax1 = plt.subplot(2, 1, 1)\n",
    "    ax2 = plt.subplot(2, 1, 2)\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(npy_path):\n",
    "        print(f\"File not found: {npy_path}\")\n",
    "        return\n",
    "\n",
    "    # 加载运动数据\n",
    "    motion_data = np.load(npy_path)  # 假定形状为 [njoints, nfeats, nframes]\n",
    "    #motion_data = motion_data.transpose(2, 0, 1)  # 转为 [nframes, njoints, nfeats]\n",
    "    # 转换为 PyTorch 张量\n",
    "    ax1.plot(motion_data[:, 15, 0])\n",
    "    #设置标题\n",
    "    ax1.set_title('Original Motion')\n",
    "    \n",
    "    motion_data = simulate_diffusion(motion_data,num_steps=step,beta_end=beta_end)\n",
    "    print(motion_data.shape)\n",
    "    ax2.plot(motion_data[:, 15, 0])\n",
    "    #设置标题\n",
    "    ax2.set_title('Low Pass Motion')\n",
    "    plt.savefig('./low_pass.png')\n",
    "    plt.show()\n",
    "\n",
    "    # 设置输出路径\n",
    "    filename = os.path.basename(npy_path).replace('.npy', '.mp4')\n",
    "    out_path = os.path.join(out_dir, filename)\n",
    "\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # 调用 plot_3d_motion 函数生成动画\n",
    "    plot_3d_motion(\n",
    "        save_path=out_path,          # 保存路径\n",
    "        kinematic_tree=t2m_kinematic_chain,  # 骨架结构\n",
    "        joints=motion_data,          # 运动数据 [nframes, njoints, nfeats]\n",
    "        title=text,    # 动画标题\n",
    "        dataset=\"humanml\",           # 数据集名\n",
    "        fps=fps                      # 帧率\n",
    "    )\n",
    "\n",
    "    print(f\"Animation saved at: {out_path}\")\n",
    "\n",
    "\n",
    "# 示例调用\n",
    "if __name__ == \"__main__\":\n",
    "    # 修改为你的 .npy 文件路径\n",
    "    npy_file = \"/home/user/dxc/motion/StableMoFusion/checkpoints/t2m/t2m_condunet1d_2/samples_iter350000_seed0_motion_text/joints_npy/01.npy\"\n",
    "    output_dir = \"./animations\"\n",
    "    text = \"Motion Animation\"\n",
    "    # 调用函数生成动画\n",
    "    #load_and_visualize_motion(npy_file, output_dir, text)\n",
    "\n",
    "    for i in range(3):\n",
    "        load_and_visualize_motion(npy_file, output_dir+f'/{i}_', text,i*20,beta_end=0.0003)\n",
    "\n",
    "    load_and_visualize_motion(npy_file, output_dir+f'/{3}_', text,30,beta_end=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file = \"/home/user/dxc/motion/StableMoFusion/checkpoints/t2m/t2m_condunet1d_2/samples_iter350000_seed0_motion_text/joints_npy/00.npy\"\n",
    "motion_data = np.load(npy_file)  # 假定形状为 [njoints, nfeats, nframes]\n",
    "    \n",
    "for i in range(3):\n",
    "    motion_data_ = simulate_diffusion(motion_data,num_steps=i*20,beta_end=0.0003)\n",
    "    np.save(f'/home/user/dxc/motion/motion-diffusion-model/diff_2/0diffusion_{i*10}.npy',motion_data_)\n",
    "\n",
    "motion_data_ = simulate_diffusion(motion_data,num_steps=3*10,beta_end=0.002)\n",
    "np.save(f'/home/user/dxc/motion/motion-diffusion-model/diff_2/0diffusion_{30}.npy',motion_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "def dct_low_pass_filter(data, axis=0, keep_ratio=0.05):\n",
    "    \"\"\"\n",
    "    对输入矩阵进行 DCT 变换，保留低频信息，并重建矩阵。\n",
    "\n",
    "    参数:\n",
    "    - data: np.ndarray\n",
    "      输入数据，形状为 [nframes, njoints, nfeats]。\n",
    "    - axis: int, 默认 0\n",
    "      指定进行 DCT 的轴（例如时间轴 nframes）。\n",
    "    - keep_ratio: float, 默认 0.1\n",
    "      保留的低频系数比例，范围为 (0, 1)。\n",
    "\n",
    "    返回:\n",
    "    - reconstructed_data: np.ndarray\n",
    "      经过低频保留并重建的数据，形状与原始数据一致。\n",
    "    - low_freq_dct: np.ndarray\n",
    "      只保留低频信息的 DCT 系数矩阵。\n",
    "    \"\"\"\n",
    "    # 确保 keep_ratio 合法\n",
    "    if not (0 < keep_ratio <= 1):\n",
    "        raise ValueError(\"keep_ratio 必须在 (0, 1] 范围内。\")\n",
    "    \n",
    "    # 计算保留的频率数量\n",
    "    n_elements = data.shape[axis]\n",
    "    keep_freq = int(n_elements * keep_ratio)\n",
    "    \n",
    "    # 对指定轴进行 DCT\n",
    "    dct_data = dct(data, axis=axis, norm='ortho')\n",
    "    \n",
    "    # 构造低频矩阵\n",
    "    low_freq_dct = np.zeros_like(dct_data)\n",
    "    slicer = [slice(None)] * data.ndim  # 构造切片\n",
    "    slicer[axis] = slice(0, keep_freq)  # 设置低频范围\n",
    "    low_freq_dct[tuple(slicer)] = dct_data[tuple(slicer)]\n",
    "    \n",
    "    # 逆 DCT 重建数据\n",
    "    reconstructed_data = idct(low_freq_dct, axis=axis, norm='ortho')\n",
    "    \n",
    "    return reconstructed_data, low_freq_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file = \"/home/user/dxc/motion/motion-diffusion-model/dataset/HumanML3D/new_joints/000021.npy\"\n",
    "motion_data = np.load(npy_file)  # 假定形状为 [njoints, nfeats, nframes]\n",
    "motion_data__,_ = dct_low_pass_filter(motion_data)\n",
    "np.save('/home/user/dxc/motion/motion-diffusion-model/diff/dct/motion_data__.npy',motion_data__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ./home/user/dxc/motion/motion-diffusion-model/save_best/mdm_50_combine/args.json\n",
    "#查看是否存在\n",
    "if os.path.exists('./save_best/mdm_50_combine/args.json'):\n",
    "    print('存在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./save_best/mdm_50_combine/args.json', 'r') as fr:\n",
    "        model_args = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 196)\n",
      "[[[ 0.00000000e+00 -7.36560556e-04 -1.57794368e-03 ... -5.19648828e-02\n",
      "   -5.20743504e-02 -5.22104166e-02]\n",
      "  [ 7.78719187e-01  7.78956890e-01  7.77924299e-01 ...  7.74039328e-01\n",
      "    7.75357604e-01  7.75219738e-01]\n",
      "  [ 0.00000000e+00  2.64728931e-03  5.11339586e-03 ...  2.36279324e-01\n",
      "    2.37292543e-01  2.38193572e-01]]\n",
      "\n",
      " [[ 6.03522584e-02  5.94979562e-02  5.86216189e-02 ...  3.24979424e-03\n",
      "    2.97518820e-03  2.82195956e-03]\n",
      "  [ 7.03007817e-01  7.03235090e-01  7.02137887e-01 ...  6.98936284e-01\n",
      "    7.00213313e-01  7.00051248e-01]\n",
      "  [-2.34513767e-02 -2.08462551e-02 -1.84465125e-02 ...  2.01107979e-01\n",
      "    2.01998755e-01  2.02962339e-01]]\n",
      "\n",
      " [[-4.64284904e-02 -4.71853763e-02 -4.80665341e-02 ... -1.03518993e-01\n",
      "   -1.03871301e-01 -1.04204856e-01]\n",
      "  [ 6.86301589e-01  6.86456501e-01  6.85359776e-01 ...  6.81296408e-01\n",
      "    6.82738841e-01  6.82619870e-01]\n",
      "  [-3.80563997e-02 -3.52552235e-02 -3.25080082e-02 ...  2.08193466e-01\n",
      "    2.08958283e-01  2.09769651e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.07126611e-01 -3.06610316e-01 -3.07803392e-01 ... -3.72048229e-01\n",
      "   -3.70489210e-01 -3.69659245e-01]\n",
      "  [ 1.06638396e+00  1.06822801e+00  1.06803381e+00 ...  1.02955604e+00\n",
      "    1.03079653e+00  1.03143632e+00]\n",
      "  [-5.59019558e-02 -5.56479879e-02 -5.50332256e-02 ...  2.63603628e-01\n",
      "    2.64845043e-01  2.65905976e-01]]\n",
      "\n",
      " [[ 2.76603580e-01  2.74766296e-01  2.72721440e-01 ...  2.21448511e-01\n",
      "    2.21269041e-01  2.21118331e-01]\n",
      "  [ 7.91149497e-01  7.93555975e-01  7.93719530e-01 ...  7.66387820e-01\n",
      "    7.68158078e-01  7.68733382e-01]\n",
      "  [-2.91768517e-02 -2.50966307e-02 -2.12137699e-02 ...  1.64431021e-01\n",
      "    1.62045330e-01  1.60540819e-01]]\n",
      "\n",
      " [[-2.50503659e-01 -2.51784563e-01 -2.54520983e-01 ... -3.26779664e-01\n",
      "   -3.26255202e-01 -3.25552136e-01]\n",
      "  [ 8.07451189e-01  8.09896231e-01  8.09119701e-01 ...  7.66453445e-01\n",
      "    7.67211795e-01  7.68403590e-01]\n",
      "  [-9.27201584e-02 -9.13572907e-02 -8.67208689e-02 ...  2.19467834e-01\n",
      "    2.18120068e-01  2.17820972e-01]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "npy_file = \"/home/user/dxc/motion/motion-diffusion-model/save_best/mdm_50_combine/samples_mdm_50_combine_000440000_seed10_a_person_walks_forward__and_pretends_to_be_a_chicken/results.npy\"\n",
    "motion_data = np.load(npy_file, allow_pickle=True)  # Set allow_pickle to True\n",
    "#print(motion_data)\n",
    "#print(motion_data.item())\n",
    "data_content = motion_data.item()\n",
    "motion_array = data_content['motion']\n",
    "print(motion_array[1].shape)\n",
    "print(motion_array[1])\n",
    "transposed_matrix = np.transpose(motion_array[2], (2, 0, 1))\n",
    "\n",
    "# 保存为 .npy 文件\n",
    "np.save(\"./v_m/MDM3\", transposed_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
